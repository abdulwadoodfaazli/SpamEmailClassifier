{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0AUwbFEaMiWi"
      },
      "source": [
        "# Spam classifier"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-26T18:21:06.553305Z",
          "start_time": "2022-10-26T18:21:06.548561Z"
        },
        "id": "Vf1CKWTgNJds"
      },
      "source": [
        "### Step 1: Download dataset\n",
        "Downloading examples of spam and ham from Apache SpamAssassinâ€™s public datasets and splitting the datasets into a training set and a test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:05:59.155299Z",
          "start_time": "2022-10-27T05:05:58.015019Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbs5g3YbuH59",
        "outputId": "fef74a0b-2b22-435b-e9ea-2b2739bc0014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of training samples: 2436\n",
            "The number of test samples: 610\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "from urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import shutil\n",
        "import sklearn.utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def download_dataset():\n",
        "\n",
        "    def download_url(url, dataset_dir=\"data\"):\n",
        "\n",
        "        tar_dir = os.path.join(dataset_dir, \"tar\")\n",
        "        if not os.path.isdir(tar_dir):\n",
        "            os.makedirs(tar_dir)\n",
        "\n",
        "        filename = url.rsplit(\"/\", 1)[-1]\n",
        "        tarpath = os.path.join(tar_dir, filename)\n",
        "\n",
        "        try:\n",
        "            tarfile.open(tarpath)\n",
        "        except:\n",
        "            urlretrieve(url, tarpath)\n",
        "\n",
        "        with tarfile.open(tarpath) as tar:\n",
        "            dirname = os.path.join(dataset_dir, tar.getnames()[0])\n",
        "            if os.path.isdir(dirname):\n",
        "                shutil.rmtree(dirname)\n",
        "            tar.extractall(path=dataset_dir)\n",
        "\n",
        "            cmds_path = os.path.join(dirname, \"cmds\")\n",
        "            if os.path.isfile(cmds_path):\n",
        "                os.remove(cmds_path)\n",
        "\n",
        "        return dirname\n",
        "\n",
        "    def load_dataset(dirpath):\n",
        "        files = []\n",
        "        filepaths = glob.glob(dirpath + \"/*\")\n",
        "        for path in filepaths:\n",
        "            with open(path, \"rb\") as f:\n",
        "                byte_content = f.read()\n",
        "                str_content = byte_content.decode(\"utf-8\", errors=\"ignore\")\n",
        "                files.append(str_content)\n",
        "        return files\n",
        "\n",
        "    spam_url = \"https://spamassassin.apache.org/old/publiccorpus/20050311_spam_2.tar.bz2\"\n",
        "    easy_ham_url = \"https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2\"\n",
        "    hard_ham_dir = \"https://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2\"\n",
        "\n",
        "    spam = load_dataset(download_url(spam_url))\n",
        "    easy_ham = load_dataset(download_url(easy_ham_url))\n",
        "    hard_ham = load_dataset(download_url(hard_ham_dir))\n",
        "\n",
        "    X = spam + easy_ham + hard_ham\n",
        "    y = np.concatenate((\n",
        "        np.ones(len(spam)),\n",
        "        np.zeros(len(easy_ham) + len(hard_ham)),\n",
        "    ))\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Download dataset.\n",
        "X, y = download_dataset()\n",
        "\n",
        "# Split dataset into training and testing sets.\n",
        "X, y = sklearn.utils.shuffle(X, y, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=42)\n",
        "\n",
        "print(f\"The number of training samples: {len(X_train)}\")\n",
        "print(f\"The number of test samples: {len(X_test)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N4RYzHc0vsyi"
      },
      "source": [
        "### Step 2: Feature extraction\n",
        "\n",
        "Doing some data cleaning and feature extraction:\n",
        "\n",
        "- Transforming an email into a (sparse) vector that indicates the presence or absence of each possible word. For example, if all emails only ever contain four words, \"Hello,\" \"how,\" \"are,\" \"you,\" then the email \"Hello you Hello Hello you\" would be converted into a vector [1, 0, 0, 1] (meaning [\"Hello\" is present, \"how\" is absent, \"are\" is absent, \"you\" is present]), or [3, 0, 0, 2] if counting the number of occurrences of each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:05:59.258405Z",
          "start_time": "2022-10-27T05:05:59.252825Z"
        },
        "id": "fegetO2HwHBo"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "class EmailCleaner(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self,\n",
        "                 no_header=True,\n",
        "                 to_lowercase=True,\n",
        "                 url_to_word=True,\n",
        "                 num_to_word=True,\n",
        "                 remove_punc=True):\n",
        "        self.no_header = no_header\n",
        "        self.to_lowercase = to_lowercase\n",
        "        self.url_to_word = url_to_word\n",
        "        self.num_to_word = num_to_word\n",
        "        self.remove_punc = remove_punc\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X_cleaned = []\n",
        "        for email in X:\n",
        "            if self.no_header:\n",
        "                email = EmailCleaner.remove_header(email)\n",
        "            if self.to_lowercase:\n",
        "                email = EmailCleaner.lower_letters(email)\n",
        "\n",
        "            email_words = email.split()\n",
        "            if self.url_to_word:\n",
        "                email_words = EmailCleaner.convert_url_to_word(email_words)\n",
        "            if self.num_to_word:\n",
        "                email_words = EmailCleaner.convert_num_to_word(email_words)\n",
        "            email = \" \".join(email_words)\n",
        "            if self.remove_punc:\n",
        "                email = EmailCleaner.remove_punctuation(email)\n",
        "            X_cleaned.append(email)\n",
        "        return X_cleaned\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_header(email):\n",
        "        return email[email.index(\"\\n\\n\"):]\n",
        "\n",
        "    @staticmethod\n",
        "    def is_url(s):\n",
        "        url = re.match(\n",
        "            \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|\"\n",
        "            \"[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", s)\n",
        "        return url is not None\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_url_to_word(words):\n",
        "        for i, word in enumerate(words):\n",
        "            if EmailCleaner.is_url(word):\n",
        "                words[i] = \"URL\"\n",
        "        return words\n",
        "\n",
        "    @staticmethod\n",
        "    def lower_letters(email):\n",
        "        return email.lower()\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_num_to_word(words):\n",
        "        for i in range(len(words)):\n",
        "          try:\n",
        "            words[i] = int(words[i])\n",
        "            words[i] = \"NUM\"\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "        return words\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_punctuation(email):\n",
        "        email = re.sub(r\"[^\\w\\s]\", \"\", email)\n",
        "        return email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:06:00.474628Z",
          "start_time": "2022-10-27T05:06:00.471273Z"
        },
        "id": "K4EEbHrnNJdy"
      },
      "outputs": [],
      "source": [
        "# Here are some unit tests to check code.\n",
        "\n",
        "# Check lower_letters().\n",
        "src_string = \"Message-Id: <LISTMANAGERSQL-25343\"\n",
        "dst_string = \"message-id: <listmanagersql-25343\"\n",
        "assert EmailCleaner.lower_letters(src_string) == dst_string\n",
        "\n",
        "# Check convert_num_to_word().\n",
        "src_string = \"Date: Wed, 10 Jul 2002\"\n",
        "src_words = src_string.split()\n",
        "dst_words = [\"Date:\", \"Wed,\", \"NUM\", \"Jul\", \"NUM\"]\n",
        "assert EmailCleaner.convert_num_to_word(src_words) == dst_words\n",
        "\n",
        "# Check remove_punctuation().\n",
        "src_string = \"superstars -- you'll find investing more fun...\"\n",
        "dst_string = \"superstars  youll find investing more fun\"\n",
        "assert EmailCleaner.remove_punctuation(src_string) == dst_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:06:02.761239Z",
          "start_time": "2022-10-27T05:06:01.254913Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7iNL7yNJdy",
        "outputId": "f9966a0d-eef4-4d9f-d0d2-50ff23405dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2436, 109039)\n",
            "(610, 109039)\n"
          ]
        }
      ],
      "source": [
        "# Step 1 of pipeline: data cleaning.\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "email_cleaner = EmailCleaner()\n",
        "\n",
        "# Step 2 of pipeline: CountVectorizer.\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Build pipeline.\n",
        "prepare_pipeline = Pipeline([\n",
        "    (\"email_cleaner\", email_cleaner),\n",
        "    (\"count_vectorizer\", count_vectorizer),\n",
        "])\n",
        "\n",
        "# Run preprocessing.\n",
        "X_all = X_train + X_test\n",
        "prepare_pipeline.fit(X_all)\n",
        "X_all = prepare_pipeline.transform(X_all)\n",
        "num_train = len(X_train)\n",
        "X_train = X_all[:num_train]\n",
        "X_test = X_all[num_train:]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AZYuW1qnvth8"
      },
      "source": [
        "### Step 3: Train a spam classifier\n",
        "\n",
        "Building a spam classifier, and training a classifier with the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:06:25.443785Z",
          "start_time": "2022-10-27T05:06:25.420443Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2BOl47eNJd0",
        "outputId": "9b19828b-bee5-4e6d-88e2-6b7467b21688"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=100, random_state=0, solver='liblinear')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "      \n",
        "logis = LogisticRegression(C=100, random_state=0, solver=\"liblinear\")\n",
        "\n",
        "logis.fit(X_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O81xjIAjNJd0"
      },
      "source": [
        "### Step 4: Evaluating the classifier\n",
        "\n",
        "Testing the classifier with the test set and printing the precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:06:26.371331Z",
          "start_time": "2022-10-27T05:06:26.364811Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QsNCDPcNJd1",
        "outputId": "09e3cf63-60b7-4d19-b349-57c8b5617100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The precision score for Logistic Regression individually is 0.98195\n",
            "The recall score for Logistic Regression individually is 0.97143\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "y_pred = logis.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "ps = precision_score(y_true=y_test, y_pred=y_pred)\n",
        "rs = recall_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(f\"The precision score for Logistic Regression individually is {ps:.5f}\")\n",
        "print(f\"The recall score for Logistic Regression individually is {rs:.5f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTbxtjvHohqJ"
      },
      "source": [
        "### Step 5: Ensemble of classifiers\n",
        "\n",
        "1. Implementing 4 new classifiers (in total, we have 5 classifiers now).\n",
        "2. Using hard or soft voting to ensemble those classifiers.\n",
        "3. Train our ensemble model on the training set. Reporting training/testing precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-27T05:06:29.164535Z",
          "start_time": "2022-10-27T05:06:28.530051Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwS_cYldop6_",
        "outputId": "5da9620b-7f5d-462a-f0b9-f048bfdac43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******************* For Individual Classifiers *******************\n",
            "\n",
            "The accuracy score for Logistic Regression individually is 0.97869\n",
            "\n",
            "The accuracy score for Perceptron individually is 0.96393\n",
            "\n",
            "The accuracy score for SVM individually is 0.97705\n",
            "\n",
            "The accuracy score for Decision Tree individually is 0.92459\n",
            "\n",
            "The accuracy score for KNN individually is 0.91967\n",
            "\n",
            "******************* For Ensemble *******************\n",
            "\n",
            "The accuracy score for ensemble using train set is 1.00000\n",
            "\n",
            "The precision score for ensemble using train set is 1.00000\n",
            "\n",
            "The recall score for ensemble using train set is 1.00000\n",
            "\n",
            "\n",
            "The accuracy score for ensemble using test set is 0.98689\n",
            "\n",
            "The precision score for ensemble using test set is 0.98921\n",
            "\n",
            "The recall score for ensemble using test set is 0.98214\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "print(\"******************* For Individual Classifiers *******************\\n\")\n",
        "\n",
        "print(f\"The accuracy score for Logistic Regression individually is {acc:.5f}\\n\")\n",
        "\n",
        "# Perceptron\n",
        "perc = Perceptron()\n",
        "perc.fit(X_train, y_train)\n",
        "perc_pred = perc.predict(X_test)\n",
        "perc_acc = accuracy_score(y_true=y_test, y_pred=perc_pred)\n",
        "print(f\"The accuracy score for Perceptron individually is {perc_acc:.5f}\\n\")\n",
        "\n",
        "# SVM\n",
        "svm = SVC(kernel=\"linear\", C=1, random_state=1)\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "svm_acc = accuracy_score(y_true=y_test, y_pred=svm_pred)\n",
        "print(f\"The accuracy score for SVM individually is {svm_acc:.5f}\\n\")\n",
        "\n",
        "# Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, random_state=2)\n",
        "tree.fit(X_train, y_train)\n",
        "tree_pred = tree.predict(X_test)\n",
        "tree_acc = accuracy_score(y_true=y_test, y_pred=tree_pred)\n",
        "print(f\"The accuracy score for Decision Tree individually is {tree_acc:.5f}\\n\")\n",
        "\n",
        "# KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric=\"minkowski\")\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "knn_acc = accuracy_score(y_true=y_test, y_pred=knn_pred)\n",
        "print(f\"The accuracy score for KNN individually is {knn_acc:.5f}\\n\")\n",
        "\n",
        "print(\"******************* For Ensemble *******************\\n\")\n",
        "\n",
        "# Ensemble\n",
        "estimators = [(\"logis\", logis), (\"perc\", perc), (\"svm\", svm), (\"tree\", tree), (\"knn\", knn)]\n",
        "ensemble = VotingClassifier(estimators=estimators)\n",
        "ensemble.fit(X_train, y_train)\n",
        "ensemble_pred_train = ensemble.predict(X_train)\n",
        "ensemble_acc_train = accuracy_score(y_true=y_train, y_pred=ensemble_pred_train)\n",
        "ensemble_pre_train = precision_score(y_true=y_train, y_pred=ensemble_pred_train)\n",
        "ensemble_rec_train = recall_score(y_true=y_train, y_pred=ensemble_pred_train)\n",
        "\n",
        "print(f\"The accuracy score for ensemble using train set is {ensemble_acc_train:.5f}\\n\")\n",
        "print(f\"The precision score for ensemble using train set is {ensemble_pre_train:.5f}\\n\")\n",
        "print(f\"The recall score for ensemble using train set is {ensemble_rec_train:.5f}\\n\\n\")\n",
        "\n",
        "ensemble_pred_test = ensemble.predict(X_test)\n",
        "ensemble_acc_test = accuracy_score(y_true=y_test, y_pred=ensemble_pred_test)\n",
        "ensemble_pre_test = precision_score(y_true=y_test, y_pred=ensemble_pred_test)\n",
        "ensemble_rec_test = recall_score(y_true=y_test, y_pred=ensemble_pred_test)\n",
        "\n",
        "print(f\"The accuracy score for ensemble using test set is {ensemble_acc_test:.5f}\\n\")\n",
        "print(f\"The precision score for ensemble using test set is {ensemble_pre_test:.5f}\\n\")\n",
        "print(f\"The recall score for ensemble using test set is {ensemble_rec_test:.5f}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "49c48b447b9efd9c07d32c0dec9df5e0c02b4225e51c3003920687e790460610"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
